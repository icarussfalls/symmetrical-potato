{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6519139,"sourceType":"datasetVersion","datasetId":3768725},{"sourceId":7289216,"sourceType":"datasetVersion","datasetId":4227311},{"sourceId":7298513,"sourceType":"datasetVersion","datasetId":4233810}],"dockerImageVersionId":30302,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas_ta\nimport pandas_ta as ta\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:21:44.419059Z","iopub.execute_input":"2024-02-20T06:21:44.419423Z","iopub.status.idle":"2024-02-20T06:21:59.920171Z","shell.execute_reply.started":"2024-02-20T06:21:44.419342Z","shell.execute_reply":"2024-02-20T06:21:59.919247Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pandas_ta\n  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pandas_ta) (1.3.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pandas_ta) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pandas_ta) (2022.1)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pandas_ta) (1.21.6)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->pandas_ta) (1.15.0)\nBuilding wheels for collected packages: pandas_ta\n  Building wheel for pandas_ta (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218923 sha256=a41420789dbefdf2917c4b23783fcdc6a5d1a7e879ca5387d817ac9201658816\n  Stored in directory: /root/.cache/pip/wheels/0b/81/f0/cca85757840e4616a2c6b9fe12569d97d324c27cac60724c58\nSuccessfully built pandas_ta\nInstalling collected packages: pandas_ta\nSuccessfully installed pandas_ta-0.3.14b0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, datetime\nimport tensorflow as tf\nfrom tensorflow.keras.models import *\nfrom keras.initializers import glorot_uniform\nfrom tensorflow.keras.layers import *\nprint('Tensorflow version: {}'.format(tf.__version__))\nimport keras\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nplt.style.use('seaborn')\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats.mstats import winsorize, trimboth\n","metadata":{"id":"f70536b2","outputId":"7270d1ad-7807-435a-ce01-c1851b37c2bf","execution":{"iopub.status.busy":"2024-02-20T06:22:21.615048Z","iopub.execute_input":"2024-02-20T06:22:21.615441Z","iopub.status.idle":"2024-02-20T06:22:28.239913Z","shell.execute_reply.started":"2024-02-20T06:22:21.615407Z","shell.execute_reply":"2024-02-20T06:22:28.239098Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Tensorflow version: 2.6.4\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32\nseq_len = 60\n\nd_k = 256\nd_v = 256\nn_heads = 12\nff_dim = 256\n#!pip install pandas_ta","metadata":{"id":"9efca2e1","execution":{"iopub.status.busy":"2024-02-20T06:22:48.992732Z","iopub.execute_input":"2024-02-20T06:22:48.993932Z","iopub.status.idle":"2024-02-20T06:22:48.998481Z","shell.execute_reply.started":"2024-02-20T06:22:48.993892Z","shell.execute_reply":"2024-02-20T06:22:48.997547Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"IBM_path = '/kaggle/input/lstmbtcusdt/BTCUSDTlstm.csv'\n\ndf = pd.read_csv(IBM_path, delimiter=',', usecols= ['Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Quote asset volume', 'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume']\n)\ndf = df.drop(df.index[:50]).drop(df.index[-1])\n\n# Replace 0 to avoid dividing by 0 later on\ndf['Volume'].replace(to_replace=0, method='ffill', inplace=True) \ndf.sort_values('Time', inplace=True)\n\n# Determine the number of rows per day\n#rows_per_day = int(24 * 60 / 1) # assuming 1-hour intervals\n\n# Drop all rows with NaN values\ndf.dropna(how='any', axis=0, inplace=True) \n\n#Drop the Time column\ndf.drop(labels=['Time'], axis=1, inplace=True)\n\n#print(df.head())\n#print(df.shape)\nprint(df.columns)","metadata":{"id":"ab1992cf","outputId":"6f0d7c3c-9bdd-4c22-d039-27ccc1e908f8","execution":{"iopub.status.busy":"2023-09-04T02:31:01.329701Z","iopub.execute_input":"2023-09-04T02:31:01.330144Z","iopub.status.idle":"2023-09-04T02:31:02.206030Z","shell.execute_reply.started":"2023-09-04T02:31:01.330109Z","shell.execute_reply":"2023-09-04T02:31:02.204733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_moving_average(df, window=20):\n    ohlcv_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n    for column in ohlcv_columns:\n        df[column] = df[column].rolling(window=window).mean()\n    return df\n\n#df = calculate_moving_average(df)\n#print(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:22:51.583677Z","iopub.execute_input":"2024-02-20T06:22:51.584395Z","iopub.status.idle":"2024-02-20T06:22:51.589936Z","shell.execute_reply.started":"2024-02-20T06:22:51.584355Z","shell.execute_reply":"2024-02-20T06:22:51.589001Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def drop_zeros(df):\n    return df[(df != 0).all(axis=1)]\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:22:53.842147Z","iopub.execute_input":"2024-02-20T06:22:53.843197Z","iopub.status.idle":"2024-02-20T06:22:53.848234Z","shell.execute_reply.started":"2024-02-20T06:22:53.843148Z","shell.execute_reply":"2024-02-20T06:22:53.847149Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = drop_zeros(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T02:31:10.032569Z","iopub.execute_input":"2023-09-04T02:31:10.033525Z","iopub.status.idle":"2023-09-04T02:31:10.049322Z","shell.execute_reply.started":"2023-09-04T02:31:10.033487Z","shell.execute_reply":"2023-09-04T02:31:10.047674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T02:31:12.770046Z","iopub.execute_input":"2023-09-04T02:31:12.770452Z","iopub.status.idle":"2023-09-04T02:31:12.795811Z","shell.execute_reply.started":"2023-09-04T02:31:12.770419Z","shell.execute_reply":"2023-09-04T02:31:12.794610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"id":"a39ca425","outputId":"d21468c8-c8e1-4475-b94a-cba93681dc58","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,9:11]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Create a StandardScaler object\n#scaler = StandardScaler()\n\n# Fit the scaler on your data\n#scaler.fit(df[\"Eigenvalues\"].tolist() + df[\"EigenvalueRatios\"].tolist())\n\n# Scale the \"Eigenvalues\" column\n#df[\"Eigenvalues\"] = scaler.transform(df[\"Eigenvalues\"].tolist())\n\n# Scale the \"EigenvalueRatios\" column\n#df[\"EigenvalueRatios\"] = scaler.transform(df[\"EigenvalueRatios\"].tolist())\n#print(df)\n\n#from joblib import dump\n\n#dump(scaler, 'eigen_predicted.joblib')","metadata":{"execution":{"iopub.status.busy":"2024-02-20T04:45:15.884816Z","iopub.execute_input":"2024-02-20T04:45:15.885502Z","iopub.status.idle":"2024-02-20T04:45:15.890349Z","shell.execute_reply.started":"2024-02-20T04:45:15.885462Z","shell.execute_reply":"2024-02-20T04:45:15.889462Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def fill_missing_values(df):\n    # Forward fill missing values first\n    df = df.ffill()\n\n    # Interpolate any remaining missing values using linear interpolation\n    df.interpolate(method='linear', inplace=True)\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:22:57.470741Z","iopub.execute_input":"2024-02-20T06:22:57.471490Z","iopub.status.idle":"2024-02-20T06:22:57.476803Z","shell.execute_reply.started":"2024-02-20T06:22:57.471451Z","shell.execute_reply":"2024-02-20T06:22:57.475574Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#import joblib\n\n# Train the model and obtain the fitted_lambda_dict\n\n# Save the fitted_lambda_dict\n#joblib.dump(fitted_lambda_dict, 'fitted_lambda_dict.joblib')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_technical_indicators(df):\n    # Handle missing values\n    df.fillna(method='ffill', inplace=True)\n    df.dropna(how='any', axis=0, inplace=True)\n\n    # Calculate RSI\n    df['rsi'] = ta.rsi(df['Close'], length=14)\n\n    # Calculate Bollinger Bands\n    bb = ta.bbands(df['Close'], length=20, std=2)\n    df['bb_upperband'] = bb['BBU_20_2.0']\n    df['bb_middleband'] = bb['BBM_20_2.0']\n    df['bb_lowerband'] = bb['BBL_20_2.0']\n\n    # Calculate EMA\n    df['ema_30'] = ta.ema(df['Close'], length=30)\n    df['ema_50'] = ta.ema(df['Close'], length=50)\n\n    # Calculate ADX\n    adx = ta.adx(df['High'], df['Low'], df['Close'], length=14)\n    df['adx'] = adx['ADX_14']\n    df['dmp'] = adx['DMP_14']\n    df['dmn'] = adx['DMN_14']\n\n    # Calculate MACD\n    macd = ta.macd(df['Close'], fast=12, slow=26, signal=9)\n    df['macd'] = macd['MACD_12_26_9']\n    df['macd_histogram'] = macd['MACDh_12_26_9']\n    df['macd_signal'] = macd['MACDs_12_26_9']\n    \n    # Handle missing values introduced by indicator calculations\n    df.fillna(method='ffill', inplace=True)\n    df.dropna(how='any', axis=0, inplace=True)\n    \n    # Apply log differencing to numeric columns\n    numeric_cols = df.select_dtypes(include=np.number).columns\n    constant = 1e-6  # A small constant to avoid zero and negative values\n    df[numeric_cols] = np.log(df[numeric_cols] + constant).diff().fillna(0)\n\n    \n    # Fill NaN values resulting from differencing\n    df.fillna(0, inplace=True)\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:23:00.166560Z","iopub.execute_input":"2024-02-20T06:23:00.167781Z","iopub.status.idle":"2024-02-20T06:23:00.180903Z","shell.execute_reply.started":"2024-02-20T06:23:00.167735Z","shell.execute_reply":"2024-02-20T06:23:00.180079Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df = add_technical_indicators(df)\n#numeric_cols = df.select_dtypes(include=np.number).columns\n#df[numeric_cols] = np.log(df[numeric_cols]).diff()\n\ndf.fillna(method='ffill', inplace=True)\ndf.dropna(how='any', axis=0, inplace=True)\ndf = fill_missing_values(df)\ndf.dropna(how='any', axis=0, inplace=True)\n#df, fitted_lambda_dict = apply_boxcox_transformation(df)\n# Check the descriptive statistics of the DataFrame\nprint(df.describe())\n","metadata":{"execution":{"iopub.status.busy":"2023-09-04T02:31:22.911793Z","iopub.execute_input":"2023-09-04T02:31:22.912163Z","iopub.status.idle":"2023-09-04T02:31:23.508151Z","shell.execute_reply.started":"2023-09-04T02:31:22.912132Z","shell.execute_reply":"2023-09-04T02:31:23.507084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-04T02:31:32.763818Z","iopub.execute_input":"2023-09-04T02:31:32.764271Z","iopub.status.idle":"2023-09-04T02:31:32.804516Z","shell.execute_reply.started":"2023-09-04T02:31:32.764230Z","shell.execute_reply":"2023-09-04T02:31:32.803301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\n# Perform ADF test on 'Close' column\nadf_result = adfuller(df['Close'])\n\n# Extract the ADF test statistics and p-value\nadf_statistic = adf_result[0]\np_value = adf_result[1]\n\n# Print the results\nprint('ADF Statistic:', adf_statistic)\nprint('p-value:', p_value)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data(ds, scaler, seq_len=60):\n    X = []\n    y = []\n    for i in range(seq_len, len(ds) - 1):\n        df = ds[i-seq_len:i+1]  # Get the 60-row sequence\n        df_scaled = scaler.transform(df)\n\n        X.append(df_scaled[:-1])  # Append all rows except the last one to X\n        y.append(df_scaled[-1, 3])  # Append the \"Close\" column of the last row to y\n\n    return np.array(X), np.array(y)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T16:11:07.604759Z","iopub.execute_input":"2023-12-28T16:11:07.605257Z","iopub.status.idle":"2023-12-28T16:11:07.614845Z","shell.execute_reply.started":"2023-12-28T16:11:07.605218Z","shell.execute_reply":"2023-12-28T16:11:07.612998Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def data(ds, scaler, seq_len=60, cumulative_steps=[5, 10]):\n    X = []\n    y = []\n    for i in range(seq_len, len(ds)):\n        df = ds[i - seq_len:i + 1]  # Get the 60-row sequence\n        df_scaled = scaler.transform(df)\n\n        X.append(df_scaled[:-1])  # Append all rows except the last one to X\n        \n        # Calculate the cumulative change in the \"Close\" price over specified steps\n        cum_changes = []\n        for steps in cumulative_steps:\n            start_index = i - seq_len\n            end_index = i + steps\n            cum_change = np.sum(ds[start_index:end_index, 3])\n            cum_changes.append(cum_change)\n        \n        y.append(cum_changes)\n\n    return np.array(X), np.array(y)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:44:08.471753Z","iopub.execute_input":"2024-02-20T06:44:08.472529Z","iopub.status.idle":"2024-02-20T06:44:08.480752Z","shell.execute_reply.started":"2024-02-20T06:44:08.472492Z","shell.execute_reply":"2024-02-20T06:44:08.479625Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"'''Create indexes to split dataset'''\n\ntimes = sorted(df.index.values)\nlast_10pct = sorted(df.index.values)[-int(0.1*len(times))] # Last 10% of series\nlast_20pct = sorted(df.index.values)[-int(0.2*len(times))] # Last 20% of series\n\n###############################################################################\n'''Create training, validation and test split'''\n\ndf_train = df[(df.index < last_20pct)]  # Training data are 80% of total data\ndf_val = df[(df.index >= last_20pct) & (df.index < last_10pct)]\ndf_test = df[(df.index >= last_10pct)]\n\n\n# Convert pandas columns into arrays\ntrain_data = df_train.values\nval_data = df_val.values\ntest_data = df_test.values\nprint('Training data shape: {}'.format(train_data.shape))\nprint('Validation data shape: {}'.format(val_data.shape))\nprint('Test data shape: {}'.format(test_data.shape))\n\ndf_train.head()\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Retain columns 9 and 10\n#train_cols_9_10 = train_data[:, 9:11]\n\n# Delete columns 9 and 10\n#train_data_del = np.delete(train_data, [9, 10], axis=1)\n#print(train_data_del.shape)\n\n# Scale the remaining columns\nscaler = StandardScaler()\nscaler.fit(train_data)\n\n\n\n# Training data\nX_train, y_train = data(train_data, scaler)\n\n# Validation data\nX_val, y_val = data(val_data, scaler)\n\n# Test data\nX_test, y_test = data(test_data, scaler)\n\n\nprint('Training set shape', X_train.shape, y_train.shape)\nprint('Validation set shape', X_val.shape, y_val.shape)\nprint('Testing set shape' ,X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T12:48:40.438532Z","iopub.execute_input":"2024-02-19T12:48:40.439021Z","iopub.status.idle":"2024-02-19T12:48:40.818244Z","shell.execute_reply.started":"2024-02-19T12:48:40.438977Z","shell.execute_reply":"2024-02-19T12:48:40.816416Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/388992563.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m'''Create indexes to split dataset'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlast_10pct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Last 10% of series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlast_20pct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Last 20% of series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-02-19T13:22:25.090136Z","iopub.execute_input":"2024-02-19T13:22:25.090573Z","iopub.status.idle":"2024-02-19T13:22:25.147332Z","shell.execute_reply.started":"2024-02-19T13:22:25.090536Z","shell.execute_reply":"2024-02-19T13:22:25.146116Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"            Open      High       Low     Close    Volume  Quote asset volume  \\\n118     0.000000  0.000000  0.000000  0.000000  0.000000            0.000000   \n119    -0.000480 -0.000383 -0.000451 -0.000324 -0.027886            0.196118   \n120    -0.000324 -0.000518 -0.000498 -0.000616  0.013630            0.473478   \n121    -0.000616 -0.000581 -0.000548 -0.000543 -0.003332           -0.493068   \n122    -0.000543 -0.000572 -0.000479 -0.000673 -0.007034            0.290537   \n...          ...       ...       ...       ...       ...                 ...   \n143135  0.000120  0.000062  0.000153  0.000235 -0.048512           -0.045093   \n143136  0.000235  0.000190  0.000253  0.000168 -0.054627           -0.010422   \n143137  0.000168  0.000144  0.000131  0.000187  0.024014            0.828491   \n143138  0.000187  0.000438  0.000348  0.000509  0.114138            0.844741   \n143139  0.000507  0.000712  0.000637  0.000707  0.170992            0.659545   \n\n        Number of trades  Taker buy base asset volume  \\\n118             0.000000                     0.000000   \n119             0.019803                    -0.071832   \n120             0.183138                    -0.084861   \n121            -0.116763                     0.105428   \n122            -0.018519                    -0.155427   \n...                  ...                          ...   \n143135         -0.187808                     0.224399   \n143136          0.163602                    -0.272813   \n143137          0.576912                     0.918294   \n143138          0.672290                     0.935604   \n143139          0.512410                     0.655164   \n\n        Taker buy quote asset volume       rsi  ...  bb_middleband  \\\n118                         0.000000  0.000000  ...       0.000000   \n119                        -0.070692 -0.057998  ...      -0.000220   \n120                        -0.084486 -0.109010  ...      -0.000262   \n121                         0.103239 -0.093552  ...      -0.000293   \n122                        -0.156957 -0.112481  ...      -0.000330   \n...                              ...       ...  ...            ...   \n143135                      0.225695  0.132273  ...      -0.000071   \n143136                     -0.272222  0.075835  ...      -0.000060   \n143137                      0.918786  0.071662  ...      -0.000047   \n143138                      0.939078  0.139429  ...      -0.000010   \n143139                      0.659344  0.114566  ...       0.000032   \n\n        bb_lowerband    ema_30    ema_50       adx       dmp       dmn  \\\n118         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n119        -0.000600 -0.000218 -0.000153  0.019133 -0.059143  0.046618   \n120        -0.000650 -0.000244 -0.000171  0.018989 -0.059763  0.052858   \n121        -0.000671 -0.000263 -0.000186  0.018759 -0.060208  0.058617   \n122        -0.000715 -0.000289 -0.000205  0.018165 -0.059978  0.040139   \n...              ...       ...       ...       ...       ...       ...   \n143135      0.000035 -0.000006 -0.000033 -0.000150  0.013979 -0.069783   \n143136      0.000067  0.000005 -0.000025 -0.029819  0.165078 -0.068424   \n143137      0.000091  0.000017 -0.000016 -0.050374  0.088391 -0.069170   \n143138      0.000031  0.000049  0.000004 -0.040301  0.318123 -0.071937   \n143139     -0.000129  0.000091  0.000032  0.024525  0.374085 -0.074142   \n\n            macd  macd_histogram  macd_signal  \n118     0.000000        0.000000          0.0  \n119     0.000000        0.000000          0.0  \n120     0.000000        0.000000          0.0  \n121     0.000000        0.000000          0.0  \n122     0.000000        0.000000          0.0  \n...          ...             ...          ...  \n143135  0.000000        0.000000          0.0  \n143136  0.000000        0.000000          0.0  \n143137  0.000000        0.000000          0.0  \n143138  0.000000        2.206148          0.0  \n143139  1.820685        0.805134          0.0  \n\n[143022 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Quote asset volume</th>\n      <th>Number of trades</th>\n      <th>Taker buy base asset volume</th>\n      <th>Taker buy quote asset volume</th>\n      <th>rsi</th>\n      <th>...</th>\n      <th>bb_middleband</th>\n      <th>bb_lowerband</th>\n      <th>ema_30</th>\n      <th>ema_50</th>\n      <th>adx</th>\n      <th>dmp</th>\n      <th>dmn</th>\n      <th>macd</th>\n      <th>macd_histogram</th>\n      <th>macd_signal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>118</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>-0.000480</td>\n      <td>-0.000383</td>\n      <td>-0.000451</td>\n      <td>-0.000324</td>\n      <td>-0.027886</td>\n      <td>0.196118</td>\n      <td>0.019803</td>\n      <td>-0.071832</td>\n      <td>-0.070692</td>\n      <td>-0.057998</td>\n      <td>...</td>\n      <td>-0.000220</td>\n      <td>-0.000600</td>\n      <td>-0.000218</td>\n      <td>-0.000153</td>\n      <td>0.019133</td>\n      <td>-0.059143</td>\n      <td>0.046618</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>-0.000324</td>\n      <td>-0.000518</td>\n      <td>-0.000498</td>\n      <td>-0.000616</td>\n      <td>0.013630</td>\n      <td>0.473478</td>\n      <td>0.183138</td>\n      <td>-0.084861</td>\n      <td>-0.084486</td>\n      <td>-0.109010</td>\n      <td>...</td>\n      <td>-0.000262</td>\n      <td>-0.000650</td>\n      <td>-0.000244</td>\n      <td>-0.000171</td>\n      <td>0.018989</td>\n      <td>-0.059763</td>\n      <td>0.052858</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>-0.000616</td>\n      <td>-0.000581</td>\n      <td>-0.000548</td>\n      <td>-0.000543</td>\n      <td>-0.003332</td>\n      <td>-0.493068</td>\n      <td>-0.116763</td>\n      <td>0.105428</td>\n      <td>0.103239</td>\n      <td>-0.093552</td>\n      <td>...</td>\n      <td>-0.000293</td>\n      <td>-0.000671</td>\n      <td>-0.000263</td>\n      <td>-0.000186</td>\n      <td>0.018759</td>\n      <td>-0.060208</td>\n      <td>0.058617</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>-0.000543</td>\n      <td>-0.000572</td>\n      <td>-0.000479</td>\n      <td>-0.000673</td>\n      <td>-0.007034</td>\n      <td>0.290537</td>\n      <td>-0.018519</td>\n      <td>-0.155427</td>\n      <td>-0.156957</td>\n      <td>-0.112481</td>\n      <td>...</td>\n      <td>-0.000330</td>\n      <td>-0.000715</td>\n      <td>-0.000289</td>\n      <td>-0.000205</td>\n      <td>0.018165</td>\n      <td>-0.059978</td>\n      <td>0.040139</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>143135</th>\n      <td>0.000120</td>\n      <td>0.000062</td>\n      <td>0.000153</td>\n      <td>0.000235</td>\n      <td>-0.048512</td>\n      <td>-0.045093</td>\n      <td>-0.187808</td>\n      <td>0.224399</td>\n      <td>0.225695</td>\n      <td>0.132273</td>\n      <td>...</td>\n      <td>-0.000071</td>\n      <td>0.000035</td>\n      <td>-0.000006</td>\n      <td>-0.000033</td>\n      <td>-0.000150</td>\n      <td>0.013979</td>\n      <td>-0.069783</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>143136</th>\n      <td>0.000235</td>\n      <td>0.000190</td>\n      <td>0.000253</td>\n      <td>0.000168</td>\n      <td>-0.054627</td>\n      <td>-0.010422</td>\n      <td>0.163602</td>\n      <td>-0.272813</td>\n      <td>-0.272222</td>\n      <td>0.075835</td>\n      <td>...</td>\n      <td>-0.000060</td>\n      <td>0.000067</td>\n      <td>0.000005</td>\n      <td>-0.000025</td>\n      <td>-0.029819</td>\n      <td>0.165078</td>\n      <td>-0.068424</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>143137</th>\n      <td>0.000168</td>\n      <td>0.000144</td>\n      <td>0.000131</td>\n      <td>0.000187</td>\n      <td>0.024014</td>\n      <td>0.828491</td>\n      <td>0.576912</td>\n      <td>0.918294</td>\n      <td>0.918786</td>\n      <td>0.071662</td>\n      <td>...</td>\n      <td>-0.000047</td>\n      <td>0.000091</td>\n      <td>0.000017</td>\n      <td>-0.000016</td>\n      <td>-0.050374</td>\n      <td>0.088391</td>\n      <td>-0.069170</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>143138</th>\n      <td>0.000187</td>\n      <td>0.000438</td>\n      <td>0.000348</td>\n      <td>0.000509</td>\n      <td>0.114138</td>\n      <td>0.844741</td>\n      <td>0.672290</td>\n      <td>0.935604</td>\n      <td>0.939078</td>\n      <td>0.139429</td>\n      <td>...</td>\n      <td>-0.000010</td>\n      <td>0.000031</td>\n      <td>0.000049</td>\n      <td>0.000004</td>\n      <td>-0.040301</td>\n      <td>0.318123</td>\n      <td>-0.071937</td>\n      <td>0.000000</td>\n      <td>2.206148</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>143139</th>\n      <td>0.000507</td>\n      <td>0.000712</td>\n      <td>0.000637</td>\n      <td>0.000707</td>\n      <td>0.170992</td>\n      <td>0.659545</td>\n      <td>0.512410</td>\n      <td>0.655164</td>\n      <td>0.659344</td>\n      <td>0.114566</td>\n      <td>...</td>\n      <td>0.000032</td>\n      <td>-0.000129</td>\n      <td>0.000091</td>\n      <td>0.000032</td>\n      <td>0.024525</td>\n      <td>0.374085</td>\n      <td>-0.074142</td>\n      <td>1.820685</td>\n      <td>0.805134</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>143022 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport joblib\nimport os\nfrom sklearn.utils import resample\n\n# Define a function for preprocessing a single cryptocurrency pair\ndef preprocess_pair(df):\n    times = sorted(df.index.values)\n    last_10pct = sorted(df.index.values)[-int(0.1*len(times))] # Last 10% of series\n    last_20pct = sorted(df.index.values)[-int(0.2*len(times))] # Last 20% of series\n\n    ###############################################################################\n    '''Create training, validation and test split'''\n\n    df_train = df[(df.index < last_20pct)]  # Training data are 80% of total data\n    df_val = df[(df.index >= last_20pct) & (df.index < last_10pct)]\n    df_test = df[(df.index >= last_10pct)]\n\n\n    # Convert pandas columns into arrays\n    train_data = df_train.values\n    val_data = df_val.values\n    test_data = df_test.values\n\n\n    # Scale the remaining columns\n    scaler = StandardScaler()\n    scaler.fit(train_data)\n\n    # Training data\n    X_train, y_train = data(train_data, scaler)\n    print(y_train)\n\n    # Validation data\n    X_val, y_val = data(val_data, scaler)\n\n    # Test data\n    X_test, y_test = data(test_data, scaler)\n    \n    # Store the scaler for the current asset pair\n    scalers[pair] = scaler\n\n    # Save the scaler for the current asset pair\n    scaler_filename = 'scaler_' + pair + '.joblib'\n    joblib.dump(scaler, os.path.join(scaler_dir, scaler_filename))\n\n    return X_train, y_train, X_val, y_val, X_test, y_test\n\n# List of cryptocurrency pairs\n#pairs = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'DOGEUSDT', 'SOLUSDT', 'BCHUSDT', 'LINKUSDT', 'XRPUSDT']\n\npairs = ['BTCUSDT']\n# Create directory to store scalers if it doesn't exist\nscaler_dir = 'scalers'\nos.makedirs(scaler_dir, exist_ok=True)\n\n# Load and preprocess the DataFrames separately\nscalers = {}\n\nX_train_scaled = []\ny_train_scaled = []\nX_val_scaled = []\ny_val_scaled = []\nX_test_scaled = []\ny_test_scaled = []\n\n# Iterate through cryptocurrency pairs\nfor pair in pairs:\n    filename = '/kaggle/input/data-archive/' + pair + '.csv'\n    df = pd.read_csv(filename, delimiter=',', usecols= ['Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Quote asset volume', 'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume']\n)\n    df = df.drop(df.index[:50]).drop(df.index[-1])\n\n    # Replace 0 to avoid dividing by 0 later on\n    df['Volume'].replace(to_replace=0, method='ffill', inplace=True) \n    df.sort_values('Time', inplace=True)\n\n    # Determine the number of rows per day\n    #rows_per_day = int(24 * 60 / 1) # assuming 1-hour intervals\n\n    # Drop all rows with NaN values\n    df.dropna(how='any', axis=0, inplace=True) \n\n    #Drop the Time column\n    df.drop(labels=['Time'], axis=1, inplace=True)\n    df = calculate_moving_average(df)\n    df = add_technical_indicators(df)\n\n    df.fillna(method='ffill', inplace=True)\n    df.dropna(how='any', axis=0, inplace=True)\n    df = fill_missing_values(df)\n    df.dropna(how='any', axis=0, inplace=True)\n    \n    \n    X_train_seq, y_train_seq, X_val_seq, y_val_seq, X_test_seq, y_test_seq = preprocess_pair(df)\n\n    # Store the scaled and sequenced data\n    X_train_scaled.extend(X_train_seq)\n    y_train_scaled.extend(y_train_seq)\n    X_val_scaled.extend(X_val_seq)\n    y_val_scaled.extend(y_val_seq)\n    X_test_scaled.extend(X_test_seq)\n    y_test_scaled.extend(y_test_seq)\n\n# Convert lists to NumPy arrays\nX_train_scaled_combined = np.array(X_train_scaled)\ny_train_scaled_combined = np.array(y_train_scaled)\nX_val_scaled_combined = np.array(X_val_scaled)\ny_val_scaled_combined = np.array(y_val_scaled)\nX_test_scaled_combined = np.array(X_test_scaled)\ny_test_scaled_combined = np.array(y_test_scaled)\n\n# Print the shapes of the combined scaled and sequenced datasets\nprint('Training set shape:', X_train_scaled_combined.shape, y_train_scaled_combined.shape)\nprint('Validation set shape:', X_val_scaled_combined.shape, y_val_scaled_combined.shape)\nprint('Test set shape:', X_test_scaled_combined.shape, y_test_scaled_combined.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:44:14.046730Z","iopub.execute_input":"2024-02-20T06:44:14.047137Z","iopub.status.idle":"2024-02-20T06:44:31.283483Z","shell.execute_reply.started":"2024-02-20T06:44:14.047100Z","shell.execute_reply":"2024-02-20T06:44:31.282454Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"[[-0.006405   -0.0073196 ]\n [-0.00663878 -0.00746225]\n [-0.00721973 -0.00777438]\n ...\n [ 0.07256562  0.07256562]\n [ 0.07054031  0.07054031]\n [ 0.0682516   0.0682516 ]]\nTraining set shape: (120470, 60, 21) (120470, 2)\nValidation set shape: (15006, 60, 21) (15006, 2)\nTest set shape: (15006, 60, 21) (15006, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"def assign_labels(cumulative_changes):\n    labels = np.zeros((cumulative_changes.shape[0], 3))  # Initialize labels array\n    \n    # Iterate over each row of cumulative changes\n    for i, (change1, change2) in enumerate(cumulative_changes):\n        if change2 < change1 and change2 < 0:  # If second change is smaller than the first and negative\n            labels[i, 1] = 1  # Label as bearish\n        elif change2 > change1 and change2 > 0:  # If second change is greater than the first and positive\n            labels[i, 2] = 1  # Label as bullish\n        else:\n            labels[i, 0] = 1  # Label as natural\n        \n    return labels\n\n\ny_train_scaled_combined = assign_labels(y_train_scaled_combined)\ny_val_scaled_combined = assign_labels(y_val_scaled_combined)\ny_test_scaled_combined = assign_labels(y_test_scaled_combined)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:44:47.155910Z","iopub.execute_input":"2024-02-20T06:44:47.156446Z","iopub.status.idle":"2024-02-20T06:44:47.508228Z","shell.execute_reply.started":"2024-02-20T06:44:47.156397Z","shell.execute_reply":"2024-02-20T06:44:47.507196Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"X_train = X_train_scaled_combined \ny_train = y_train_scaled_combined\nX_val = X_val_scaled_combined \ny_val = y_val_scaled_combined \nX_test = X_test_scaled_combined \ny_test = y_test_scaled_combined","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:11:04.007473Z","iopub.execute_input":"2023-08-17T07:11:04.007877Z","iopub.status.idle":"2023-08-17T07:11:04.013396Z","shell.execute_reply.started":"2023-08-17T07:11:04.007845Z","shell.execute_reply":"2023-08-17T07:11:04.012259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = '/kaggle/working/combined_dataa.npz'\nnp.savez(save_path,\n         X_train_scaled_combined=X_train_scaled_combined,\n         y_train_scaled_combined=y_train_scaled_combined,\n         X_val_scaled_combined=X_val_scaled_combined,\n         y_val_scaled_combined=y_val_scaled_combined,\n         X_test_scaled_combined=X_test_scaled_combined,\n         y_test_scaled_combined=y_test_scaled_combined)\n\nprint('Data saved to', save_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T16:13:44.965348Z","iopub.execute_input":"2023-12-28T16:13:44.965794Z","iopub.status.idle":"2023-12-28T16:14:25.083189Z","shell.execute_reply.started":"2023-12-28T16:13:44.965758Z","shell.execute_reply":"2023-12-28T16:14:25.081952Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Data saved to /kaggle/working/combined_dataa.npz\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Create memory-mapped files for your datasets\nX_train_scaled_combined = np.memmap('X_train_scaled_combined.dat', dtype='float32', mode='w+', shape=(866741, 60, 21))\ny_train_scaled_combined = np.memmap('y_train_scaled_combined.dat', dtype='float32', mode='w+', shape=(866741,))\nX_val_scaled_combined = np.memmap('X_val_scaled_combined.dat', dtype='float32', mode='w+', shape=(107915, 60, 21))\ny_val_scaled_combined = np.memmap('y_val_scaled_combined.dat', dtype='float32', mode='w+', shape=(107915,))\nX_test_scaled_combined = np.memmap('X_test_scaled_combined.dat', dtype='float32', mode='w+', shape=(107913, 60, 21))\ny_test_scaled_combined = np.memmap('y_test_scaled_combined.dat', dtype='float32', mode='w+', shape=(107913,))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:01:40.774506Z","iopub.execute_input":"2023-12-29T16:01:40.774909Z","iopub.status.idle":"2023-12-29T16:01:40.784624Z","shell.execute_reply.started":"2023-12-29T16:01:40.774875Z","shell.execute_reply":"2023-12-29T16:01:40.783604Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load the combined datasets from the file into the same variable names\nsave_path = '/kaggle/input/datasetzip/combined_dataa.npz'\nloaded_data = np.load(save_path)\n# Load the data into memory-mapped arrays\nX_train_scaled_combined[:] = loaded_data['X_train_scaled_combined']\ny_train_scaled_combined[:] = loaded_data['y_train_scaled_combined']\nX_val_scaled_combined[:] = loaded_data['X_val_scaled_combined']\ny_val_scaled_combined[:] = loaded_data['y_val_scaled_combined']\nX_test_scaled_combined[:] = loaded_data['X_test_scaled_combined']\ny_test_scaled_combined[:] = loaded_data['y_test_scaled_combined']\n\n\n# Print the shapes of the loaded datasets\nprint('Loaded Training set shape:', X_train_scaled_combined.shape, y_train_scaled_combined.shape)\nprint('Loaded Validation set shape:', X_val_scaled_combined.shape, y_val_scaled_combined.shape)\nprint('Loaded Test set shape:', X_test_scaled_combined.shape, y_test_scaled_combined.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:01:42.568495Z","iopub.execute_input":"2023-12-29T16:01:42.569442Z","iopub.status.idle":"2023-12-29T16:03:23.420711Z","shell.execute_reply.started":"2023-12-29T16:01:42.569410Z","shell.execute_reply":"2023-12-29T16:03:23.419709Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Loaded Training set shape: (866741, 60, 21) (866741,)\nLoaded Validation set shape: (107915, 60, 21) (107915,)\nLoaded Test set shape: (107913, 60, 21) (107913,)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-22T12:04:04.169536Z","iopub.execute_input":"2023-09-22T12:04:04.170159Z","iopub.status.idle":"2023-09-22T12:05:38.885602Z","shell.execute_reply.started":"2023-09-22T12:04:04.170103Z","shell.execute_reply":"2023-09-22T12:05:38.881493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from joblib import dump\n\ndump(scaler, 'train_scalers_predicted.joblib')","metadata":{"execution":{"iopub.status.busy":"2023-12-28T17:25:34.645539Z","iopub.execute_input":"2023-12-28T17:25:34.646038Z","iopub.status.idle":"2023-12-28T17:25:34.671906Z","shell.execute_reply.started":"2023-12-28T17:25:34.645999Z","shell.execute_reply":"2023-12-28T17:25:34.670686Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_28/2213753765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_scalers_predicted.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"],"ename":"NameError","evalue":"name 'scaler' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import tensorflow as tf\n@tf.autograph.experimental.do_not_convert\ndef lr_scheduler(epoch, lr, warmup_epochs=10, decay_epochs1=20, decay_epochs2=30, initial_lr=1e-6, base_lr=1e-3, min_lr=5e-5):\n    if epoch <= warmup_epochs:\n        pct = epoch / warmup_epochs\n        return ((base_lr - initial_lr) * pct) + initial_lr\n\n    if epoch > warmup_epochs and epoch <= warmup_epochs + decay_epochs1:\n        pct = 1 - ((epoch - warmup_epochs) / decay_epochs1)\n        return ((base_lr - min_lr) * pct) + min_lr\n    \n    if epoch > warmup_epochs + decay_epochs1 and epoch <= warmup_epochs + decay_epochs2:\n        pct = 1 - ((epoch - warmup_epochs - decay_epochs1) / (decay_epochs2 - decay_epochs1))\n        return ((base_lr/10 - min_lr) * pct) + min_lr\n    \n    return min_lr\n","metadata":{"id":"79478125","execution":{"iopub.status.busy":"2024-02-20T06:24:00.988378Z","iopub.execute_input":"2024-02-20T06:24:00.989135Z","iopub.status.idle":"2024-02-20T06:24:00.997229Z","shell.execute_reply.started":"2024-02-20T06:24:00.989092Z","shell.execute_reply":"2024-02-20T06:24:00.996099Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom tensorflow.keras.callbacks import Callback\n\nclass R2Callback(Callback):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n        \n    def on_epoch_end(self, epoch, logs=None):\n        if logs is None:\n            logs = {}\n        if epoch % 10 == 0:  # Print R2 score every 5th epoch\n            y_pred = self.model.predict(self.X)\n            r2 = r2_score(self.y, y_pred)\n            logs['r2'] = r2\n            print(f\"val_r2: {r2:.4f}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:04:05.804713Z","iopub.execute_input":"2023-12-29T16:04:05.805475Z","iopub.status.idle":"2023-12-29T16:04:05.875994Z","shell.execute_reply.started":"2023-12-29T16:04:05.805437Z","shell.execute_reply":"2023-12-29T16:04:05.874977Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras.regularizers import l2\nimport tensorflow as tf\nimport numpy as np\n\nclass MyModel(tf.keras.Model):\n    def __init__(self, input_shape, num_layers, d_model, num_heads, dff, dropout_rate, l2_reg):\n        super(MyModel, self).__init__()\n        self.num_layers = num_layers\n        self.l2_reg = l2_reg\n        self.d_model = d_model\n\n        self.embedding = tf.keras.layers.Dense(d_model, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))\n        self.pos_encoding = self.positional_encoding(input_shape[0], d_model)\n        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n        self.transformer_blocks = [self.transformer_block(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n        self.lstm = tf.keras.layers.LSTM(d_model, return_sequences=True)\n        self.attention = tf.keras.layers.Attention()\n        self.fc = tf.keras.layers.Dense(d_model, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))\n        self.final_layer = tf.keras.layers.Dense(1, activation='linear', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))\n\n    def call(self, inputs):\n        x = self.embedding(inputs)\n        x += self.pos_encoding[:, :tf.shape(x)[1], :]\n        x = self.dropout(x)\n        for i in range(self.num_layers):\n            x = self.transformer_blocks[i](x)\n        x = self.lstm(x)\n        x = self.attention([x, x])\n        x = self.fc(x)\n        x = self.final_layer(x[:, -1, :])\n        return x\n\n    def transformer_block(self, d_model, num_heads, dff, dropout_rate):\n        inputs = tf.keras.Input(shape=(None, d_model))\n        attn = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n        attn = tf.keras.layers.Dropout(dropout_rate)(attn)\n        out1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attn)\n\n        ffn = tf.keras.Sequential([\n            tf.keras.layers.Dense(dff, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(self.l2_reg)),\n            tf.keras.layers.Dense(d_model, kernel_regularizer=tf.keras.regularizers.l2(self.l2_reg))\n        ])\n        ffn_output = ffn(out1)\n        ffn_output = tf.keras.layers.Dropout(dropout_rate)(ffn_output)\n        out2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n        return tf.keras.Model(inputs=inputs, outputs=out2)\n\n    def get_angles(self, pos, i):\n        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(self.d_model))\n        return pos * angle_rates\n\n    def positional_encoding(self, position, d_model):\n        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :])\n        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n        pos_encoding = angle_rads[np.newaxis, ...]\n        return tf.constant(pos_encoding, dtype=tf.float32)\n\n\n# Define the model\n#model = MyModel((X_train.shape[1],), num_layers=4, d_model=128, num_heads=8, dff=512, dropout_rate=0.2)\n\n# Compile the model\n#model.compile(loss='mean_squared_error', optimizer='adam')\n\n\n# Train the model\n#history = model.fit(X_train, y_train, batch_size=1024, epochs=30, validation_data=(X_val, y_val), callbacks=[EarlyStopping(patience=3, restore_best_weights=True), LearningRateScheduler(lr_scheduler), R2Callback(X_train, y_train)])\n\n# Evaluate the model on test data\n#test_loss = model.evaluate(X_test, y_test)\n#test_r2 = r2_score(y_test, model.predict(X_test))\n#print(\"Test loss: {:.4f}\".format(test_loss))\n#print(\"Test R2 score: {:.4f}\".format(test_r2))\n","metadata":{"id":"fa1ad4b4","outputId":"ad34e323-8494-49e3-da8a-66c846cf7a2a","execution":{"iopub.status.busy":"2023-12-29T16:04:09.283944Z","iopub.execute_input":"2023-12-29T16:04:09.284811Z","iopub.status.idle":"2023-12-29T16:04:09.309724Z","shell.execute_reply.started":"2023-12-29T16:04:09.284775Z","shell.execute_reply":"2023-12-29T16:04:09.308777Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(len(X_train_scaled_combined))\nprint(len(y_train_scaled_combined))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T04:29:40.272429Z","iopub.execute_input":"2024-02-20T04:29:40.272836Z","iopub.status.idle":"2024-02-20T04:29:40.278683Z","shell.execute_reply.started":"2024-02-20T04:29:40.272805Z","shell.execute_reply":"2024-02-20T04:29:40.277516Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"120470\n120470\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint as sp_randint\nfrom keras.wrappers.scikit_learn import KerasRegressor\n\n# Create a function to build the model\ndef build_model(num_layers, d_model, num_heads, dff, dropout_rate, l2_reg):\n    model = MyModel((X_train_scaled_combined.shape[1],), num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, l2_reg=l2_reg)\n    model.compile(loss='', optimizer='adam')\n    return model\n\n# Create the KerasRegressor wrapper\nmodel = KerasRegressor(build_fn=build_model, verbose=1)\n# Create the parameter distribution\nparam_dist = {\n    'num_layers': sp_randint(2, 5),    # Lowered lower bound\n    'd_model': sp_randint(64, 160),    # Lowered lower bound\n    'num_heads': sp_randint(3, 9),     # Lowered lower bound\n    'dff': sp_randint(256, 480),       # Lowered lower bound\n    'dropout_rate': [0.05, 0.1, 0.2],  # A few options\n    'l2_reg': [0.01, 0.05, 0.1]        # A few options\n}\n\n\n\n# Create the randomized search object\nrandom_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, scoring='neg_mean_squared_error', cv=3, n_iter=10)\n\n\n# Select a subset of data\nsubset_size = 500  # Adjust the subset size as needed\nX_train_subset = X_train_scaled_combined[:subset_size]\ny_train_subset = y_train_scaled_combined[:subset_size]\n\n\n# Perform randomized search\n#random_search.fit(X_train_subset, y_train_subset)  # X_train and y_train are your training data\n\n# Print the best hyperparameters and corresponding mean squared error\n#print(\"Best parameters: \", random_search.best_params_)\n#print(\"Best mean squared error: \", np.sqrt(-random_search.best_score_))\n\n# Get the best model\n#best_model = random_search.best_estimator_\n\n# Perform continuous optimization\n#history = best_model.fit(X_train, y_train, batch_size=1024, epochs=30, validation_data=(X_val, y_val), callbacks=[EarlyStopping(patience=3, restore_best_weights=True), LearningRateScheduler(lr_scheduler), R2Callback(X_train, y_train)])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:04:12.776557Z","iopub.execute_input":"2023-12-29T16:04:12.776995Z","iopub.status.idle":"2023-12-29T16:04:12.814406Z","shell.execute_reply.started":"2023-12-29T16:04:12.776959Z","shell.execute_reply":"2023-12-29T16:04:12.813492Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import TensorBoard\n\nclass MyModel(tf.keras.Model):\n    def __init__(self, input_shape, num_layers, d_model, num_heads, dff, dropout_rate, l2_reg):\n        super(MyModel, self).__init__()\n        self.num_layers = num_layers\n        self.l2_reg = l2_reg\n        self.d_model = d_model\n\n        self.embedding = tf.keras.layers.Dense(d_model, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))\n        self.pos_encoding = self.positional_encoding(input_shape[0], d_model)\n        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n        self.transformer_blocks = [self.transformer_block(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n        self.lstm = tf.keras.layers.LSTM(d_model, return_sequences=True)\n        self.attention = tf.keras.layers.Attention()\n        self.fc = tf.keras.layers.Dense(d_model, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))\n        self.final_layer = tf.keras.layers.Dense(3, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))\n\n    def call(self, inputs):\n        x = self.embedding(inputs)\n        x += self.pos_encoding[:, :tf.shape(x)[1], :]\n        x = self.dropout(x)\n        for i in range(self.num_layers):\n            x = self.transformer_blocks[i](x)\n        x = self.lstm(x)\n        x = self.attention([x, x])\n        x = self.fc(x)\n        x = self.final_layer(x[:, -1, :])\n        return x\n\n    def transformer_block(self, d_model, num_heads, dff, dropout_rate):\n        inputs = tf.keras.Input(shape=(None, d_model))\n        attn = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n        attn = tf.keras.layers.Dropout(dropout_rate)(attn)\n        out1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attn)\n\n        ffn = tf.keras.Sequential([\n            tf.keras.layers.Dense(dff, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(self.l2_reg)),\n            tf.keras.layers.Dense(d_model, kernel_regularizer=tf.keras.regularizers.l2(self.l2_reg))\n        ])\n        ffn_output = ffn(out1)\n        ffn_output = tf.keras.layers.Dropout(dropout_rate)(ffn_output)\n        out2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n        return tf.keras.Model(inputs=inputs, outputs=out2)\n\n    def get_angles(self, pos, i):\n        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(self.d_model))\n        return pos * angle_rates\n\n    def positional_encoding(self, position, d_model):\n        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :])\n        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n        pos_encoding = angle_rads[np.newaxis, ...]\n        return tf.constant(pos_encoding, dtype=tf.float32)\n\n\n# Define a TensorBoard callback with Kaggle's log directory\ntensorboard_callback = TensorBoard(log_dir='/kaggle/working/logs', histogram_freq=1)\n\n# Define the MirroredStrategy\nstrategy = tf.distribute.MirroredStrategy()\n\ndef build_model(num_layers, d_model, num_heads, dff, dropout_rate, l2_reg):\n    model = MyModel((X_train_scaled_combined.shape[1],), num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, l2_reg=l2_reg)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    return model\n\nparams = {'d_model': 112, 'dff': 397, 'dropout_rate': 0.2, 'l2_reg': 0.01, 'num_heads': 8, 'num_layers': 3}\n#params = random_search.best_params_\n\nwith strategy.scope():\n    best_model = build_model(**params)\n    history = best_model.fit(X_train_scaled_combined, y_train_scaled_combined, batch_size=1024, epochs=200, validation_data=(X_val_scaled_combined, y_val_scaled_combined), callbacks=[EarlyStopping(patience=10, restore_best_weights=True), LearningRateScheduler(lr_scheduler),tensorboard_callback])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:45:13.085811Z","iopub.execute_input":"2024-02-20T06:45:13.086790Z","iopub.status.idle":"2024-02-20T07:00:56.687823Z","shell.execute_reply.started":"2024-02-20T06:45:13.086749Z","shell.execute_reply":"2024-02-20T07:00:56.686907Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/200\n118/118 [==============================] - 49s 322ms/step - loss: 13.0854 - val_loss: 13.0471\nEpoch 2/200\n118/118 [==============================] - 33s 277ms/step - loss: 11.2498 - val_loss: 9.7696\nEpoch 3/200\n118/118 [==============================] - 32s 275ms/step - loss: 7.7839 - val_loss: 6.0755\nEpoch 4/200\n118/118 [==============================] - 33s 277ms/step - loss: 4.4895 - val_loss: 3.2224\nEpoch 5/200\n118/118 [==============================] - 33s 277ms/step - loss: 2.3268 - val_loss: 1.6580\nEpoch 6/200\n118/118 [==============================] - 33s 276ms/step - loss: 1.2855 - val_loss: 1.0150\nEpoch 7/200\n118/118 [==============================] - 33s 276ms/step - loss: 0.8909 - val_loss: 0.8326\nEpoch 8/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.7560 - val_loss: 0.7149\nEpoch 9/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.7062 - val_loss: 0.7194\nEpoch 10/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.6842 - val_loss: 0.6563\nEpoch 11/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.6767 - val_loss: 0.6607\nEpoch 12/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.6608 - val_loss: 0.6722\nEpoch 13/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.6526 - val_loss: 0.6506\nEpoch 14/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.6470 - val_loss: 0.6442\nEpoch 15/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.6438 - val_loss: 0.6486\nEpoch 16/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.6393 - val_loss: 0.6467\nEpoch 17/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.6380 - val_loss: 0.6443\nEpoch 18/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.6299 - val_loss: 0.6363\nEpoch 19/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.6241 - val_loss: 0.6376\nEpoch 20/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.6230 - val_loss: 0.6875\nEpoch 21/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.6184 - val_loss: 0.6458\nEpoch 22/200\n118/118 [==============================] - 33s 276ms/step - loss: 0.6144 - val_loss: 0.6531\nEpoch 23/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.6123 - val_loss: 0.6527\nEpoch 24/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.6053 - val_loss: 0.6479\nEpoch 25/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.6008 - val_loss: 0.6481\nEpoch 26/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.5971 - val_loss: 0.6537\nEpoch 27/200\n118/118 [==============================] - 33s 277ms/step - loss: 0.5929 - val_loss: 0.6587\nEpoch 28/200\n118/118 [==============================] - 33s 278ms/step - loss: 0.5881 - val_loss: 0.6568\n","output_type":"stream"}]},{"cell_type":"code","source":"#x_train = X_train_scaled_combined[:]\n#ghghghghghghghghghgh\nprint(y_train_scaled_combined)\nprint(\"Shape of y_train_scaled_combined:\", y_train_scaled_combined.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T04:41:55.451764Z","iopub.execute_input":"2024-02-20T04:41:55.452164Z","iopub.status.idle":"2024-02-20T04:41:55.458987Z","shell.execute_reply.started":"2024-02-20T04:41:55.452130Z","shell.execute_reply":"2024-02-20T04:41:55.457595Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"[[0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n ...\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]]\nShape of y_train_scaled_combined: (120470, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\ntf.config.experimental.set_visible_devices\n","metadata":{"execution":{"iopub.status.busy":"2023-09-04T03:38:26.894676Z","iopub.execute_input":"2023-09-04T03:38:26.895188Z","iopub.status.idle":"2023-09-04T03:38:26.905630Z","shell.execute_reply.started":"2023-09-04T03:38:26.895129Z","shell.execute_reply":"2023-09-04T03:38:26.903887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ghghghghghghghghghghghghghghghghghghghghghghgh\nimport tensorflow as tf\nfrom keras import backend as K\n\n# TensorFlow\ntf.keras.backend.clear_session()\n\n# Keras\nK.clear_session()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-04T03:07:03.080033Z","iopub.execute_input":"2023-09-04T03:07:03.081431Z","iopub.status.idle":"2023-09-04T03:07:03.122478Z","shell.execute_reply.started":"2023-09-04T03:07:03.081380Z","shell.execute_reply":"2023-09-04T03:07:03.121265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the best model\nfrom tensorflow.keras.models import save_model\n#ghghghghghghghghghghghghghghghghghghghghghghghghghghghghghghghghgh\n\n# Save the best model\nbest_model.save('/kaggle/working/model')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T07:02:14.893801Z","iopub.execute_input":"2024-02-20T07:02:14.894703Z","iopub.status.idle":"2024-02-20T07:02:28.467076Z","shell.execute_reply.started":"2024-02-20T07:02:14.894667Z","shell.execute_reply":"2024-02-20T07:02:28.466012Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#!pip install keras --upgrade\n#ghghghgh\n#Best parameters:  {'d_model': 76, 'dff': 629, 'dropout_rate': 0.1, 'l2_reg': 0.01, 'num_heads': 7, 'num_layers': 5}\n#Best mean squared error:  0.3272984077979012","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.show()\n#training loss in blue and the validation loss in orange\n#If the training loss is much lower than the validation loss, your model is likely overfitting. \n#If both the training and validation loss are high, your model is likely underfitting.","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:42:43.301016Z","iopub.execute_input":"2024-02-20T06:42:43.301875Z","iopub.status.idle":"2024-02-20T06:42:43.549447Z","shell.execute_reply.started":"2024-02-20T06:42:43.301833Z","shell.execute_reply":"2024-02-20T06:42:43.548528Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 576x396 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"model = load_model('/kaggle/input/modell/accur')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:32:05.884247Z","iopub.execute_input":"2023-09-22T13:32:05.884729Z","iopub.status.idle":"2023-09-22T13:32:20.715089Z","shell.execute_reply.started":"2023-09-22T13:32:05.884688Z","shell.execute_reply":"2023-09-22T13:32:20.714110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('/kaggle/working/accur', save_format='tf')\n!zip -r folder2.zip /kaggle/working/model//","metadata":{"id":"mcmhWhH89hiB","outputId":"fa69fa7a-075a-4879-eaa3-0e52f8f79132","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-20T07:02:48.221709Z","iopub.execute_input":"2024-02-20T07:02:48.222116Z","iopub.status.idle":"2024-02-20T07:02:50.302010Z","shell.execute_reply.started":"2024-02-20T07:02:48.222084Z","shell.execute_reply":"2024-02-20T07:02:50.300963Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/model// (stored 0%)\n  adding: kaggle/working/model//keras_metadata.pb (deflated 94%)\n  adding: kaggle/working/model//variables/ (stored 0%)\n  adding: kaggle/working/model//variables/variables.data-00000-of-00001 (deflated 7%)\n  adding: kaggle/working/model//variables/variables.index (deflated 76%)\n  adding: kaggle/working/model//assets/ (stored 0%)\n  adding: kaggle/working/model//saved_model.pb (deflated 88%)\n","output_type":"stream"}]},{"cell_type":"code","source":"#y_test_scaled_combined = assign_labels(y_test_scaled_combined)\ny_test_pred = best_model.predict(X_test_scaled_combined)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T07:01:34.986197Z","iopub.execute_input":"2024-02-20T07:01:34.987102Z","iopub.status.idle":"2024-02-20T07:01:43.288240Z","shell.execute_reply.started":"2024-02-20T07:01:34.987055Z","shell.execute_reply":"2024-02-20T07:01:43.287357Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Convert one-hot encoded true labels to class labels\ny_test_true_labels = np.argmax(y_test_scaled_combined, axis=1)\n\n# Convert one-hot encoded predictions to class labels\ny_test_pred_labels = np.argmax(y_test_pred, axis=1)\n\n# Calculate accuracy\naccuracy = np.mean(y_test_pred_labels == y_test_true_labels)\nprint(\"Out of Sample Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T07:01:43.678119Z","iopub.execute_input":"2024-02-20T07:01:43.678494Z","iopub.status.idle":"2024-02-20T07:01:43.685721Z","shell.execute_reply.started":"2024-02-20T07:01:43.678454Z","shell.execute_reply":"2024-02-20T07:01:43.684776Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Out of Sample Accuracy: 0.7042516326802613\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example of reshaping a 2D array to 1D\ny_train_scaled_combined_1d = y_train_scaled_combined.ravel()\ny_train_pred_1d = y_train_pred.ravel()\n\n# Create the DataFrame\ndf = pd.DataFrame({'y_true': y_train_scaled_combined_1d, 'y_pred': y_train_pred_1d})","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:39:17.580736Z","iopub.execute_input":"2023-09-22T13:39:17.581113Z","iopub.status.idle":"2023-09-22T13:39:17.617516Z","shell.execute_reply.started":"2023-09-22T13:39:17.581082Z","shell.execute_reply":"2023-09-22T13:39:17.616468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('predictions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:39:53.786020Z","iopub.execute_input":"2023-09-22T13:39:53.786851Z","iopub.status.idle":"2023-09-22T13:39:56.774974Z","shell.execute_reply.started":"2023-09-22T13:39:53.786800Z","shell.execute_reply":"2023-09-22T13:39:56.773924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the training, validation, and test sets\n#y_train_pred = model.predict(X_train_scaled_combined)\ny_val_pred = model.predict(X_val_scaled_combined)\ny_test_pred = model.predict(X_test_scaled_combined)\n\n# Plot the actual vs predicted values for the training set\n#plt.figure(figsize=(32, 16))\n#plt.plot(y_train_scaled_combined, label='Actual')\n#plt.plot(y_train_pred, label='Predicted')\n#plt.title('Training Set')\n#plt.legend()\n#plt.show()\n\n# Plot the actual vs predicted values for the validation set\nplt.figure(figsize=(32, 16))\nplt.plot(y_val_scaled_combined, label='Actual')\nplt.plot(y_val_pred, label='Predicted')\nplt.title('Validation Set')\nplt.legend()\nplt.show()\n\n# Plot the actual vs predicted values for the test set\nplt.figure(figsize=(32, 16))\nplt.plot(y_test_scaled_combined, label='Actual')\nplt.plot(y_test_pred, label='Predicted')\nplt.title('Test Set')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T12:33:35.592650Z","iopub.execute_input":"2023-09-22T12:33:35.593132Z","iopub.status.idle":"2023-09-22T12:35:00.420947Z","shell.execute_reply.started":"2023-09-22T12:33:35.593070Z","shell.execute_reply":"2023-09-22T12:35:00.419834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ny_test_pred = model.predict(X_test_scaled_combined)\n# Calculate R2 score for the test setgh\nr2 = r2_score(y_test_scaled_combined, y_test_pred)\nprint(\"R2 Score:\", r2)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T08:22:17.009167Z","iopub.execute_input":"2023-09-04T08:22:17.010300Z","iopub.status.idle":"2023-09-04T08:23:42.147907Z","shell.execute_reply.started":"2023-09-04T08:22:17.010256Z","shell.execute_reply":"2023-09-04T08:23:42.146698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = best_model","metadata":{"execution":{"iopub.status.busy":"2023-09-04T07:41:59.608220Z","iopub.execute_input":"2023-09-04T07:41:59.608688Z","iopub.status.idle":"2023-09-04T07:41:59.614336Z","shell.execute_reply.started":"2023-09-04T07:41:59.608650Z","shell.execute_reply":"2023-09-04T07:41:59.613103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}